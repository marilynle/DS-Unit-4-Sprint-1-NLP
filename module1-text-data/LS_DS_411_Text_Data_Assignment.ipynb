{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
    "<br></br>\n",
    "<br></br>\n",
    "\n",
    "# Natural Language Processing (NLP)\n",
    "## *Data Science Unit 4 Sprint 1 Assignment 1*\n",
    "\n",
    "Your goal in this assignment: find the attributes of the best & worst coffee shops in the dataset. The text is fairly raw: dates in the review, extra words in the `star_rating` column, etc. You'll probably want to clean that stuff up for a better analysis. \n",
    "\n",
    "Analyze the corpus of text using text visualizations of token frequency. Try cleaning the data as much as possible. Try the following techniques: \n",
    "- Lemmatization\n",
    "- Custom stopword removal\n",
    "\n",
    "Keep in mind the attributes of good tokens. Once you have a solid baseline, layer in the star rating in your visualization(s). Key part of this assignment - produce a write-up of the attributes of the best and worst coffee shops. Based on your analysis, what makes the best the best and the worst the worst. Use graphs and numbesr from your analysis to support your conclusions. There should be plenty of markdown cells! :coffee:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import YouTubeVideo\n",
    "\n",
    "YouTubeVideo('Jml7NVYm8cs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Marilyn Landim Esko\\\\GitHub\\\\DS-Unit-4-Sprint-1-NLP\\\\module1-text-data'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coffee_shop_name</th>\n",
       "      <th>full_review_text</th>\n",
       "      <th>star_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>The Factory - Cafe With a Soul</td>\n",
       "      <td>11/25/2016 1 check-in Love love loved the atm...</td>\n",
       "      <td>5.0 star rating</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>The Factory - Cafe With a Soul</td>\n",
       "      <td>12/2/2016 Listed in Date Night: Austin, Ambia...</td>\n",
       "      <td>4.0 star rating</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>The Factory - Cafe With a Soul</td>\n",
       "      <td>11/30/2016 1 check-in Listed in Brunch Spots ...</td>\n",
       "      <td>4.0 star rating</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>The Factory - Cafe With a Soul</td>\n",
       "      <td>11/25/2016 Very cool decor! Good drinks Nice ...</td>\n",
       "      <td>2.0 star rating</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>The Factory - Cafe With a Soul</td>\n",
       "      <td>12/3/2016 1 check-in They are located within ...</td>\n",
       "      <td>4.0 star rating</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  coffee_shop_name  \\\n",
       "0  The Factory - Cafe With a Soul    \n",
       "1  The Factory - Cafe With a Soul    \n",
       "2  The Factory - Cafe With a Soul    \n",
       "3  The Factory - Cafe With a Soul    \n",
       "4  The Factory - Cafe With a Soul    \n",
       "\n",
       "                                    full_review_text        star_rating  \n",
       "0   11/25/2016 1 check-in Love love loved the atm...   5.0 star rating   \n",
       "1   12/2/2016 Listed in Date Night: Austin, Ambia...   4.0 star rating   \n",
       "2   11/30/2016 1 check-in Listed in Brunch Spots ...   4.0 star rating   \n",
       "3   11/25/2016 Very cool decor! Good drinks Nice ...   2.0 star rating   \n",
       "4   12/3/2016 1 check-in They are located within ...   4.0 star rating   "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/LambdaSchool/DS-Unit-4-Sprint-1-NLP/master/module1-text-data/data/yelp_coffeeshop_review_data.csv\"\n",
    "\n",
    "shops = pd.read_csv(url)\n",
    "shops.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: en_core_web_lg==2.0.0 from https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-2.0.0/en_core_web_lg-2.0.0.tar.gz#egg=en_core_web_lg==2.0.0 in c:\\users\\marilyn landim esko\\anaconda3\\envs\\u4-s1-nlp\\lib\\site-packages (2.0.0)\n",
      "\n",
      "\u001b[93m    Error: Couldn't link model to 'en_core_web_lg'\u001b[0m\n",
      "    Creating a symlink in spacy/data failed. Make sure you have the required\n",
      "    permissions and try re-running the command as admin, or use a\n",
      "    virtualenv. You can still import the model as a module and call its\n",
      "    load() method, or create the symlink manually.\n",
      "\n",
      "    C:\\Users\\Marilyn Landim\n",
      "    Esko\\Anaconda3\\envs\\U4-S1-NLP\\lib\\site-packages\\en_core_web_lg -->\n",
      "    C:\\Users\\Marilyn Landim\n",
      "    Esko\\Anaconda3\\envs\\U4-S1-NLP\\lib\\site-packages\\spacy\\data\\en_core_web_lg\n",
      "\n",
      "\n",
      "\u001b[93m    Creating a shortcut link for 'en' didn't work (maybe you don't have\n",
      "    admin permissions?), but you can still load the model via its full\n",
      "    package name: nlp = spacy.load('{name}')\u001b[0m\n",
      "    Download successful but linking failed\n",
      "\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'spacy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-64668288817f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;31m# NLP Libraries\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'python -m spacy download en_core_web_lg'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mspacy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mspacy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtokenizer\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mTokenizer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstem\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPorterStemmer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'spacy'"
     ]
    }
   ],
   "source": [
    "# Start here\n",
    "\n",
    "\"\"\"\n",
    "Import Statements\n",
    "\"\"\"\n",
    "\n",
    "# Base\n",
    "from collections import Counter\n",
    "import re\n",
    " \n",
    "import pandas as pd\n",
    "\n",
    "# Plotting\n",
    "import squarify\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# NLP Libraries\n",
    "!python -m spacy download en_core_web_lg\n",
    "import spacy\n",
    "from spacy.tokenizer import Tokenizer\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How do we want to analyze these coffee shop tokens? \n",
    "\n",
    "- Overall Word / Token Count\n",
    "- View Counts by Rating \n",
    "- *Hint:* a 'bad' coffee shops has a rating betweeen 1 & 3 based on the distribution of ratings. A 'good' coffee shop is a 4 or 5. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overall Word / Token Count\n",
    "shops['tokens'] = shops['full_review_text'].apply(tokenize)\n",
    "df['tokens'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View Counts by Rating \n",
    "print(shops['star_rating'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Can visualize the words with the greatest difference in counts between 'good' & 'bad'?\n",
    "\n",
    "Couple Notes: \n",
    "- Rel. freq. instead of absolute counts b/c of different numbers of reviews\n",
    "- Only look at the top 5-10 words with the greatest differences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1dCb1q8XphcP",
    "toc-hr-collapsed": true
   },
   "source": [
    "## Stretch Goals\n",
    "\n",
    "* Analyze another corpus of documents - such as Indeed.com job listings ;).\n",
    "* Play with the Spacy API to\n",
    " - Extract Named Entities\n",
    " - Extracting 'noun chunks'\n",
    " - Attempt Document Classification with just Spacy\n",
    " - *Note:* This [course](https://course.spacy.io/) will be of interesting in helping you with these stretch goals. \n",
    "* Try to build a plotly dash app with your text data \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "LS_DS_421_Text_Data_Assignment.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "U4-S1-NLP (Python3)",
   "language": "python",
   "name": "u4-s1-nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
